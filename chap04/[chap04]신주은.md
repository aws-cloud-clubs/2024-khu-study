> 처리율 제한 장치 : 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치
> 
- 예시
    - 사용자는 2회/s 이상 새 글 작성 x
    - 동일 IP 주소로 10개/day 이상 계정 생성 x
    - 동일 디바이스로 5회 리워드/week 이상 요청 x
- API에 처리율 제한 장치를 두면 좋은 점
    - DoS 공격에 의한 자원 고갈을 방지
    ex) 트위터, 구글 독스
    - 비용 절감
        - 서버 개수 감소
        - api 우선순위에 비례한 자원 할당
        - 외부 api 사용 시, 횟수 제한
    - 서버 과부화 방지

# 1단계 | 문제 이해 및 설계 범위 확정

- 클라이언트 vs 서버 측 제한 장치 → 서버 측
- api 호출 기준 - ip 주소 vs 사용자 id → 전부
- 시스템 규모 → 대규모
- 분산 환경 동작
- 독립적 vs 종속적 → 판단
- 사용자에게 피드백

## 요구사항

- 설정된 처리율 초과 요청 시 정확히 제한
- 응답시간에 영향 주면 x
- 가능한 적은 메모리
- 분산형 처리율 제한 : 여러 서버 및 프로세스에서 공유
- 예외 처리 : 요청 제한 시 피드백
- 높은 결함 감내성 : 시스템 전체에 영향 x

# 2단계 | 개략적 설계안 제시 및 동의 구하기

- 지나친 복잡성은 지양
- 기본적인 클라이언트-서버 통신 모델

## 처리율 제한 장치 위치

- 클라이언트
    - 일반적으로 클라이언트는 처리율 제한을 안정적으로 걸 수 없음
    - 클라이언트 요청은 쉽게 위변조가 가능
    - 모든 클라이언트의 구현을 통제하는 것도 어려움
- 서버
    1. api 서버에 처리율 제한 장치 두기
    2. 처리율 제한 미들웨어를 만들기
    - 클라우드 마이크로서비스의 경우, 처리율 제한 장치는 보통 **API 게이트웨이**라 불리는 컴포넌트에 구현
        - 클라우드 마이크로서비스 : sw 애플리케이션 또는 기능 개발 시, 독립적으로 구축하고 관리할 수 있는 분산된 모듈 집합으로 다양한 애플리케이션 서비스를 실행하도록 하는 아키텍처 방법
    - API 게이트웨이
        - 처리율 제한을 지원하는 미들웨어
        - SSL 종단(termination)
        - 사용자 인증(authentication)
        - IP 허용 목록(whitelist) 관리 등을 지원하는 위탁관리형 서비스
        - 클라우드 업체가 유지 보수를 담당하는 서비스
- 기준
    - 프로그래밍 언어, 캐시 서비스 등 현재 사용하고 있는 기술 스택 점검
    - 사업에 맞는 처리율 제한 알고리즘 탐색
    - 마이크로서비스 기반, API 게이트웨이를 설계에 이미 포함 → 게이트웨이에 처리율 제한 기능 포함
    - 시간 고려

## 처리율 제한 알고리즘

- 토큰 버킷 (token bucket)
- 누출 버킷 (leaky bucket)
- 고정 윈도 카운터 (fixed window counter)
- 이동 윈도 로그 (sliding window log)
- 이동 윈도 카운터 (sliding window counter)

### 토큰 버킷 알고리즘

- 간단함. 보편적임
- 토큰 버킷
    - 지정된 용량을 갖는 컨테이너
    - 주기적으로 사전 설정 토큰이 채워짐
    - 버킷이 가득 찰 시, 추가로 공급된 버킷은 버려짐
- 요청이 도착하면 버킷에 충분한 토큰이 있는지 검사 후, 각 요청은 처리될 때마다 하나의 토큰 사용
- 인자
    1. 버킷 크기 : 버킷에 담을 수 있는 토큰의 최대 개수
    2. 토큰 공급률 : 초당 몇 개의 토큰이 버킷에 공급되는가
- 장점
    - 구현 쉬움
    - 메모리 사용 효율적
    - 짧은 시간 집중되는 트래필 처리 가능
- 단점
    - 인자를 적절히 튜닝하기 어려움

### 누출 버킷 알고리즘

- 요청 처리율이 고정되어 있는 토큰 버킷 알고리즘
- FIFO로 구현
- 요청 도착 시 큐가 가득 차 있는지 확인 → 빈자리면 큐에 요청 추가
- 큐가 가득 차 있으면 새 요청 버림
- 지정된 시간마다 큐에서 요청을 꺼내 처리
- 인자
    1. 버킷 크기 : 큐 사이즈와 같은 값
    2. 처리율 : 지정된 시간 당 몇 개의 항목을 처리할지 지정하는 값
- 장점
    - 큐의 크기 제한 → 메모리 사용량 효율적
    - 고정된 처리율 → 안정적 출력이 필요한 경우 적합
- 단점
    - 단시간에 많은 트래픽이 몰리는 경우 큐에 오랜 요청들이 쌓임 → 요청들을 제때 처리하지 못하면 최신 요청들은 버려짐
    - 인자 튜닝하기 어려움

### 고정 윈도 카운터 알고리즘

- 타임라인 - 고정된 간격의 윈도우로 나누고, 윈도우마다 카운터 붙임
- 요청이 접수될 때마다 카운터 값 1씩 증가
- 카운터 값이 임계치에 도달 → 새로운 요청은 새 윈도우가 열릴 때까지 버려짐
- 장점
    - 메모리 효율 좋음
    - 이해가 쉬움
    - 특정한 트래픽 패턴을 처리하기에 적합함
- 단점
    - 윈도우 경계 부근에서 일시적으로 많은 트래픽이 몰려들 경우, 한도보다 많은 양의 요쳥을 처리할 수도 있음

### 이동 윈도 로깅 알고리즘

- 고정 윈도 카운터 알고리즘에 중대한 문제 존재 → 해결
- 타임스탬프를 추적 → 보통 레디스의 정렬 집합 같은 캐시에 보관
- 새 요청이 오면 만료 타임스탬프 제거
    - 만료 타임스탬프 : 값이 현재 윈도우의 시작 시점보다 오래된 타임스탬프
- 새 요청의 타임스탬프를 로그에 추가
- 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달
- 장점
    - 아주 정교함 → 허용되는 요청의 개수가 시스템의 처리율 한도를 넘지 않음
- 단점
    - 거부된 요청의 타임스탬프도 보관하기 때문에, 다량의 메모리를 사용

### 이동 윈도 카운터 알고리즘

- 고정 윈도 카운터 알고리즘 + 이동 윈도 로깅 알고리즘
- 장점
    - 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응
    - 메모리 효율이 좋음
- 단점
    - 작전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정 → 다소 느슨

### 개략적인 아키텍처

- 동작원리
    - 클라이언트가 처리율 제한 미들웨어에게 요청
    - 처리율 제한 미들웨어는 레디스의 지정 버킷에서 카운터를 가져와서 한도에 도달했는지 아닌지 검사

# 3단계 | 상세 설계

- 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가?
- 처리가 제한된 요청들은 어떻게 처리되는가?

## 처리율 제한 규칙

## 처리율 한도 초과 트래픽의 처리

- 어떤 요청이 한도 제한에 걸리면 api는 HTTP 429를 응답
- 경우에 따라서는 한도 제한에 걸린 메시지를 큐에 보관 후 처리

### 처리율 제한 장치가 사용하는 HTTP 헤더

클라이언트는 요청이 처리율 제한에 걸리고 있는지를 http 응답 헤더로 알 수 있음

## 상세 설계

- 처리율 제한 규칙 - 디스크에 보관
    - 작업 프로세스가 수시로 규칙을 디스크에서 읽어 캐시에 저장
- 클라이언트가 요청을 서버에게 보냄 → 처리율 제한 미들웨어에 도달
- 처리율 제한 미들웨어는 제한 규칙을 캐시에서 가져옴 → 카운터 및 최종 요청의 타임스탬프를 레디스 캐시에서 가져옴
    - 해당 요청이 처리율 제한에 걸리지 않음 → api 서버로 전송
    - 해당 요청이 처리율 제한에 걸림 → 429 http response

## 분산 환경에서의 처리율 제한 장치의 구현

- 단일 서버 지원의 처리율 제한 장치 구현은 비교적 쉬움
- 여러 대의 서버와 병렬 스레드 지원의 경우 다음 두 가지를 고려해야 함
    - 경쟁 조건(race condition)
    - 동기화(synchronization)

### 경쟁 조건

- 가장 널리 알려진 해결책 : 락
- 락은 시스템의 성능을 상당히 떨어뜨린다는 문제 존재
- 해결책
    - 루아 스크립트(Lua script)
    - 정렬 집합(sorted set)

```bash
race condition은 알고 있었고, 이를 lock을 통해 해결하는 것은 알고 있었다.
그런데, 락이 성능을 떨어뜨린다는 것과 대체할 수 있는 해결책이 있다는 게 좀 신기했다.
```

### 동기화 이슈

- 해결책 : 고정 세션(sticky session) 활용
    - 같은 클라이언트의 요청은 항상 같은 처리율 제한 장치로 보냄 → 추천 x
        - 확장이 불가능하고, 유연하지 않음
- 더 나은 해결책
    - 중앙 집중형 데이터 저장소 사용 - redis

### 성능 최적화

- 두 가지 지점에서 개선 가능
    1. 여러 데이터 센터 지원 문제의 지연 시간 증가로 인해 분산 에지 서버를 설치
        - 사용자의 트래픽을 가장 가까운에지 서버로 전달해서 지연시간을 감소
    2. 데이터 동기화 시 최종 일관성 모델(eventual consistency model)을 사용

### 모니터링

- 채택된 처리율 제한 알고리즘이 효과적
- 정의한 처리율 제한 규칙이 효과적

# 4단계 | 마무리

1. 알고리즘
    - 토큰 버킷
    - 누출 버킷
    - 고정 윈도 카운터
    - 이동 윈도 로그
    - 이동 윈도 카운터
- 경성 | 연성 처리율 제한
    1. 경성 처리율 제한 : 요청의 개수는 임계치를 절대 넘을 수 없음
    2. 연성 처리율 제한 : 요청 개수가 잠시 동안은 임계치를 넘을 수 있음
- 다양한 계층에서의 처리율 제한
- 처리율 제한을 회피하는 법
    - 클라이언트 측 캐시 사용 → api 호출 횟수 감소
    - 처리율 제한의 임계치를 이해하고, 단기간 동안 과도한 메시지 전송 제한
    - 예외나 에러 처리 코드를 도입해 클라이언트가 예외 상황에서 우아하게 복구 지원
    - 재시도 로직 구현 시 충분한 백오프 시간 제공
